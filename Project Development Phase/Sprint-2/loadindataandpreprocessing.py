# -*- coding: utf-8 -*-
"""LoadinDataAndPreprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13mRORr4N14yEQOWczbz4nk6r2X9HmOA9

Unzipping the Dataset
"""

!unzip "/content/Digital Naturalist Dataset.zip"

"""Importing the Required Libraries"""

from keras.preprocessing.image import ImageDataGenerator
import cv2
from os import listdir
import time

"""Data Augmentation Function"""

def hms_string(sec_elapsed):
  h = int (sec_elapsed)/ (60*60);
  m = int ((sec_elapsed % (60*60))/60)
  s = sec_elapsed % 60
  return f"{h}:{m}:{round(s,1)}"


def augment_data(file_dir, n_generated_samples, save_to_dir):
    data_gen = ImageDataGenerator(rotation_range=30, 
                                  width_shift_range=0.1,
                                  height_shift_range=0.15, 
                                  shear_range=0.25, 
                                  zoom_range = 0.2,
                                  horizontal_flip=True, 
                                  vertical_flip=False, 
                                  fill_mode='nearest',
                                  brightness_range=(0.5,1.2)
                                 )
    print(data_gen)
    for filename in listdir(file_dir):
        image = cv2.imread(file_dir + '/' + filename)
        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
        image = image.reshape((1,)+image.shape)
        save_prefix = 'aug_' + filename[:-4]    
        i=0
        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir,
                                   save_prefix=save_prefix, save_format='jpg'):
            i += 1
            if i > n_generated_samples:
                break

"""Calling the augment_data function for all the sub folders"""

start_time = time.time()

augmented_data_path = '/content/Augument Dataset'
augment_data(file_dir='/content/Digital Naturalist Dataset/Bird/Great Indian Bustard Bird', n_generated_samples=10, save_to_dir=augmented_data_path+'/Bird/GIB_AUG')
augment_data(file_dir='/content/Digital Naturalist Dataset/Bird/Spoon Billed Sandpiper Bird', n_generated_samples=10, save_to_dir=augmented_data_path+'/Bird/SPS_AUG')
augment_data(file_dir='/content/Digital Naturalist Dataset/Flower/Corpse Flower', n_generated_samples=10, save_to_dir=augmented_data_path+'/Flower/Corpse_AUG')
augment_data(file_dir='/content/Digital Naturalist Dataset/Flower/Lady Slipper Orchid Flower', n_generated_samples=10, save_to_dir=augmented_data_path+'/Flower/LS_Orchid_AUG')
augment_data(file_dir='/content/Digital Naturalist Dataset/Mammal/Pangolin Mammal', n_generated_samples=10, save_to_dir=augmented_data_path+'/Mammal/LS_Pangolin_AUG')
augment_data(file_dir='/content/Digital Naturalist Dataset/Mammal/Senenca White Deer Mammal', n_generated_samples=10, save_to_dir=augmented_data_path+'/Mammal/SW_Deer_AUG')

end_time = time.time()
execution_time = (end_time - start_time)
print(f"Elapsed time: {hms_string(execution_time)}")

"""Importing the Required Libraries


"""

import numpy as np

import tensorflow as tf
import keras
import keras.backend as K

from keras.optimizers import SGD, Adam, Adagrad, RMSprop
from keras.applications import *
from keras.preprocessing import *
from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Activation, BatchNormalization, Dropout
from keras.utils.np_utils import to_categorical
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt

import glob
from PIL import Image
import os
from os import listdir

"""Make A List Of Paths To All Folders Where You Have Data

"""

def getListOfFiles(dirName):
  listOfFile = os.listdir(dirName)
  allFiles = list()
  for fol_name in listOfFile:
    fullPath = os.path.join(dirName, fol_name)
    allFiles.append(fullPath) 
  return allFiles

dirName = '/content/Augument Dataset'
Folders = getListOfFiles(dirName)

subfolders = []
for num in range(len(Folders)):
  sub_fols = getListOfFiles(Folders[num])
  subfolders += sub_fols

print(subfolders)

"""Loading Images Into Machine Understandable Data.

"""

X_data = []
Y_data = []
id_no = 0

found = []

for paths in subfolders:

  files = glob.glob (paths + "/*.jpg")

  found.append((paths.split('/')[-2],paths.split('/')[-1]))

  for myFile in files:
    img = Image.open(myFile)

    img = img.resize((224,224), Image.ANTIALIAS)

    img = np.array(img)

    if img.shape == ((224, 224, 3)):

      X_data.append (img)
      Y_data.append (id_no)
  id_no+=1

"""Data Splitting Into Train And Test"""

print(X_data)
print(Y_data)

X = np.array(X_data)
Y = np.array(Y_data)

print("x-shape",X.shape,"y shape",Y.shape)

X = X.astype('float32')/255.0

y_cat = to_categorical(Y_data, len(subfolders))

print("X shape", X, "y_cat shape", y_cat)
print("X shape", X.shape, "y_cat shape", y_cat.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size = 0.2)

print("The model has  "+ str(len(X_train))+" inputs")